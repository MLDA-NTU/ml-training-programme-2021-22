# Neural Network

Geometric Deep Learning: [ICLR 2021 Keynote](https://www.youtube.com/watch?v=w6Pw4MOzMuo)

Universal approximation theorem: [Wikipedia](https://en.wikipedia.org/wiki/Universal_approximation_theorem)

## Feed-forward, Fully-connected Neural Network

Play with Neural Network: [TensorFlow playground](https://playground.tensorflow.org/)

Neural Network visualizer: [Netron](https://netron.app/)

- Construction as linear projection and non-linear activations
- Activation function: why we need it, common types, gradient problem
- Batch norm: why we need it, training and testing behavior, other types of norm layer
- Designing NN: depth and width
- Brief overview of data types and neural network types: convolution, recurrent, attention, graph

## Training a neural network

- Weight initialization
- Mini-batch training
- Loss function
- Optimizers: SGD, SGD with momentum, Adam, RMSprop
- Best practices: logging, checkpoints

## Common topologies

- Parallel heads (at output)
- Width expansion
- Auto-encoder / Bottleneck
- Skip-connections (ResNet, U-Net, HourGlass)
- Recurrent
